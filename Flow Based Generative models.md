Models that transform a simple probability distribution (e.g. a Gaussian) into a more complex probability distribution (e.g. the distribution of the training data) using a series of invertible transformations. These models can be trained using [[Maximum Likelihood Estimation]] or maximum likelihood density ratio estimation. Examples of flow-based generative models include the normalizing flow (NF) and the real-valued non-volume preserving (RealNVP) model.