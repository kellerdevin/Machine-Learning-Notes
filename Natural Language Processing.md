
[[Generative Models]] in NLP
In natural language processing (NLP), a generative model learns to model the probability distribution of sequences of text, and can be used to generate new text based on this learned distribution. An example of a generative model in NLP is the language model, which learns to predict the probability of a word given the context of the previous words in a sentence. The transformer, like ChatGPT, is an example of a powerful generative NLP model.

[[Discriminate Model]] in NLP
A discriminative model in NLP learns to model the decision boundary between different classes of text. An example of a discriminative model in NLP is the text classification model, which takes a sequence of text as input and outputs a label or category for that text. Support vector machines (SVMs) and logistic regression are examples of discriminative models that have been used in NLP.

Examples of NLP models: [[Transformers]], [[Few Shot Learning]], [[Recurrent Neural Networks]]

